{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa1eaff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HARSHV~1\\AppData\\Local\\Temp/ipykernel_6276/315973342.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequentialFeatureSelector\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mSFS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import csv\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bs4 as bs\n",
    "import pandas_datareader as web\n",
    "import itertools\n",
    "from itertools import chain\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68991c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.21.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in e:\\softwares\\anaconda3\\lib\\site-packages (from mlxtend) (1.7.1)\n",
      "Requirement already satisfied: setuptools in e:\\softwares\\anaconda3\\lib\\site-packages (from mlxtend) (58.0.4)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in e:\\softwares\\anaconda3\\lib\\site-packages (from mlxtend) (3.4.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in e:\\softwares\\anaconda3\\lib\\site-packages (from mlxtend) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.16.2 in e:\\softwares\\anaconda3\\lib\\site-packages (from mlxtend) (1.20.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in e:\\softwares\\anaconda3\\lib\\site-packages (from mlxtend) (1.1.0)\n",
      "Collecting scikit-learn>=1.0.2\n",
      "  Downloading scikit_learn-1.2.0-cp39-cp39-win_amd64.whl (8.3 MB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\softwares\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in e:\\softwares\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\softwares\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\softwares\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\softwares\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: six in e:\\softwares\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'E:\\\\Softwares\\\\anaconda3\\\\Lib\\\\site-packages\\\\~klearn\\\\decomposition\\\\_cdnmf_fast.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytz>=2017.3 in e:\\softwares\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\softwares\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Collecting joblib>=0.13.2\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Installing collected packages: joblib, scikit-learn, mlxtend\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db59b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tickers=[]\n",
    "\n",
    "def contains(s):\n",
    "    return not re.match(r'[^.]+$', s)\n",
    "\n",
    "def nifty50_tickers():\n",
    "    link = 'https://en.wikipedia.org/wiki/NIFTY_50'\n",
    "    response = requests.get(link)\n",
    "    soup = bs.BeautifulSoup(response.text, 'lxml')\n",
    "    table = soup.find('table', {'class' : 'wikitable sortable'}, {'id' : 'constituents'})\n",
    "    tickers=[]\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[1].text[:]\n",
    "        tickers.append(ticker)\n",
    "    for i in tickers:\n",
    "        if contains(i) != True:\n",
    "            final_tickers.append(i)\n",
    "            \n",
    "    return final_tickers\n",
    "\n",
    "nifty50_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "string=\".NS\"\n",
    "new_tickerlist = [x + string for x in final_tickers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9bbc47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = date.today() - timedelta(days=2190)\n",
    "end = date.today()\n",
    "\n",
    "if not os.path.exists('Companies'):\n",
    "    os.makedirs('Companies')\n",
    "\n",
    "for ticker in new_tickerlist:\n",
    "    if not os.path.exists('Companies/{}.csv'.format(ticker)):\n",
    "        print(\"{} - Fetching Data... \".format(ticker))\n",
    "        df = web.DataReader(ticker, 'yahoo', start, end)\n",
    "        df.to_csv('Companies/{}.csv'.format(ticker))\n",
    "    else:\n",
    "        print(\"{} - Already Fetched.!\".format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf8b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()\n",
    "\n",
    "for ticker in new_tickerlist:\n",
    "    df = pd.read_csv('Companies/{}.csv'.format(ticker))\n",
    "    df.set_index('Date', inplace=True)\n",
    "    df.rename(columns = {'Close': ticker}, inplace=True)\n",
    "    df.drop(columns = ['Open', 'High', 'Low', 'Adj Close', 'Volume'], inplace=True)\n",
    "    if main_df.empty:\n",
    "        main_df = df\n",
    "    else:\n",
    "        main_df = main_df.join(df, how='outer')\n",
    "        \n",
    "main_df = main_df.reset_index()\n",
    "main_df.set_index('Date', inplace=True)\n",
    "Dataframe = pd.concat([main_df.tail(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "high = Dataframe.copy()\n",
    "open1 = Dataframe.copy()\n",
    "low = Dataframe.copy()\n",
    "close = Dataframe.copy()\n",
    "\n",
    "high.loc[:] = np.nan\n",
    "open1.loc[:] = np.nan\n",
    "low.loc[:] = np.nan\n",
    "close.loc[:] = np.nan\n",
    "\n",
    "Datelist=[]\n",
    "\n",
    "if not os.path.exists(\"Companies_data\"):\n",
    "    os.makedirs(\"Companies_data\")\n",
    "\n",
    "for ticker in new_tickerlist:\n",
    "    with open(\"Companies_data/{}.csv\".format(ticker), 'w') as f:\n",
    "        pass\n",
    "    df = pd.read_csv('Companies/{}.csv'.format(ticker))\n",
    "    data1 = pd.concat([df.tail(2)])\n",
    "    data1.drop(df.tail(1).index,inplace=True)\n",
    "    data1.to_csv(\"Companies_data\\{}.csv\".format(ticker), header=True, index=False)\n",
    "    with open(\"Companies_data\\{}.csv\".format(ticker)) as f:\n",
    "        companies_csv = csv.DictReader(f)\n",
    "        for row in companies_csv:\n",
    "            Date = row['Date']\n",
    "            HighPrice = float(float(row['High']))\n",
    "            OpenPrice = float(float(row['Open']))\n",
    "            LowPrice = float(float(row['Low']))\n",
    "            ClosePrice = float(float(row['Close']))\n",
    "        H = HighPrice\n",
    "        O = OpenPrice\n",
    "        L = LowPrice\n",
    "        C = ClosePrice\n",
    "    Datelist.append(Date)\n",
    "    high[ticker].fillna(H, inplace=True)\n",
    "    open1[ticker].fillna(O, inplace=True)\n",
    "    low[ticker].fillna(L, inplace=True)\n",
    "    close[ticker].fillna(C, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb4a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = pd.DataFrame(columns=['Companies', '200_Moving_AVG', '50_Moving_AVG'])\n",
    "newdata['Companies'] = new_tickerlist\n",
    "mva50all, mva200all = ([] for i in range(2))\n",
    "\n",
    "for tickers in new_tickerlist:\n",
    "    df = pd.read_csv('Companies/{}.csv'.format(tickers))\n",
    "    mva50 = round(df['Close'].rolling(window=50, min_periods=0).mean(), 3)\n",
    "    mva200 = round(df['Close'].rolling(window=200, min_periods=0).mean(), 3)\n",
    "    df['50_mVA'] = mva50\n",
    "    df['200_mvA'] = mva200\n",
    "    df.to_csv('Companies/{}.csv'.format(tickers), index=False)       \n",
    "    mva50all.append(mva50.iloc[-1])\n",
    "    mva200all.append(mva200.iloc[-1])\n",
    "    \n",
    "newdata['200_Moving_AVG'] = mva200all\n",
    "newdata['50_Moving_AVG'] = mva50all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a2ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "high1,low1,open2,close1 = ([] for i in range(4))\n",
    "    \n",
    "for (colname, colval) in low.iteritems():\n",
    "    low1.append(round(float(colval), 3))\n",
    "    \n",
    "for (colname, colval) in open1.iteritems():\n",
    "    open2.append(round(float(colval), 3))\n",
    "\n",
    "for (colname, colval) in high.iteritems():\n",
    "    high1.append(round(float(colval), 3))\n",
    "    \n",
    "for (colname, colval) in close.iteritems():\n",
    "    close1.append(round(float(colval), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_values,confidence1,kfeature,kscore = ([] for i in range(4))\n",
    "\n",
    "for ticker in new_tickerlist:\n",
    "    df = pd.read_csv('Companies/{}.csv'.format(ticker), index_col=0)\n",
    "    days = 1\n",
    "    df['pred_cp'] = df['Adj Close'].shift(-days)\n",
    "    df['High'] = df['High'].shift(-days)\n",
    "    df['Low'] = df['Low'].shift(-days)\n",
    "    df['Open'] = df['Open'].shift(-days)\n",
    "    df['Close'] = df['Close'].shift(-days)\n",
    "    df.to_csv(\"Companies/{}.csv\".format(ticker), header=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    X = np.array(df[['Open', 'High', 'Low', 'Close', '50_mVA', '200_mvA']])\n",
    "    Y = np.array(df['pred_cp'])\n",
    "\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    encoded = lab_enc.fit_transform(Y)\n",
    "    knn = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "    sfs = SFS(knn, k_features=5, forward=True, floating=False, verbose=2, scoring='accuracy', cv=0)\n",
    "\n",
    "    feature_names = ('Open', 'High', 'Low', 'Close', '50_mVA', '200mVA')\n",
    "    sfs = sfs.fit(X, encoded, custom_feature_names=feature_names)\n",
    "    kfeature.append(sfs.k_feature_idx_)\n",
    "    kscore.append(sfs.k_score_)\n",
    "    \n",
    "    X = preprocessing.scale(X)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=1)\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    confidence = clf.score(X_test, Y_test)\n",
    "    confidence1.append(confidence)\n",
    "\n",
    "    X = X[:-days]\n",
    "    X_new = X[-days:]\n",
    "    prediction = clf.predict(X_new)\n",
    "    \n",
    "    predictive_values.append(float(np.ma.round(prediction, decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8400e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataframe = pd.DataFrame(columns=['Date', \n",
    "                                         'Companies', \n",
    "                                         'Open', \n",
    "                                         'High', \n",
    "                                         'Low',\n",
    "                                         'Close',\n",
    "                                         '50d Moving AVG',\n",
    "                                         '200d Moving AVG',\n",
    "                                         'Predictive Close',\n",
    "                                         'Confidence',\n",
    "                                         'k_feature',\n",
    "                                         'k_score'])\n",
    "\n",
    "merged_dataframe['Date'] = Datelist\n",
    "merged_dataframe['Companies'] = new_tickerlist\n",
    "merged_dataframe['Open'] = open2\n",
    "merged_dataframe['High'] = high1\n",
    "merged_dataframe['Low'] = low1\n",
    "merged_dataframe['Close'] = close1\n",
    "merged_dataframe['50d Moving AVG'] = mva50all\n",
    "merged_dataframe['200d Moving AVG'] = mva200all\n",
    "merged_dataframe['Predictive Close'] = predictive_values\n",
    "merged_dataframe['Confidence'] = confidence1\n",
    "merged_dataframe['k_feature'] = kfeature\n",
    "merged_dataframe['k_score'] = kscore\n",
    "\n",
    "merged_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4aa04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('Companies')\n",
    "shutil.rmtree('Companies_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87724804",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad52567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2528f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
